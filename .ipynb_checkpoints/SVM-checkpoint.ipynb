{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "import os\n",
    "\n",
    "import sox\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "import random\n",
    "\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "import opensmile\n",
    "\n",
    "path = 'data'  # download and extract files from https://github.com/aliyzd95/ShEMO-Modification/raw/main/shemo.zip\n",
    "emo_codes = {\"A\": 0, \"W\": 1, \"H\": 2, \"S\": 3, \"N\": 4, \"F\": 5}\n",
    "emo_labels = [\"anger\", \"surprise\", \"happiness\", \"sadness\", \"neutral\", \"fear\"]\n",
    "\n",
    "\n",
    "def get_emotion_label(file_name):\n",
    "    emo_code = file_name[3]\n",
    "    return emo_codes[emo_code]\n",
    "\n",
    "\n",
    "def opensmile_Functionals():\n",
    "    feature_extractor = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        verbose=True, num_workers=None,\n",
    "        sampling_rate=16000, resample=True,\n",
    "    )\n",
    "    features = []\n",
    "    emotions = []\n",
    "    for file in os.listdir(path):\n",
    "        if emo_labels[get_emotion_label(file)] != 'fear':\n",
    "            df = feature_extractor.process_file(f'{path}/{file}')\n",
    "            features.append(df)\n",
    "            emotions.append(get_emotion_label(file))\n",
    "    features = np.array(features).squeeze()\n",
    "    emotions = np.array(emotions)\n",
    "    return features, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  8.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 9.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 9.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.6min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.9min\n",
      "____________________ Support Vector Machine ____________________\n",
      "Weighted Accuracy: 74.40915409507315\n",
      "Unweighted Accuracy: 59.16878570719483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 44.0min finished\n"
     ]
    }
   ],
   "source": [
    "seed_value = 42\n",
    "import os\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "import random\n",
    "\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "#import opensmile_preprocessing\n",
    "#%run opensmile_preprocessing.ipynb\n",
    "#from opensmile_preprocessing import opensmile_Functionals, emo_labels\n",
    "#from ipynb.fs.full.<opensmile_preprocessing> import <opensmile_Functionals>\n",
    "#from ipynb.fs.full.<opensmile_preprocessing> import <emo_labels>\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def generate_confusion_matrix(cnf_matrix, classes, normalize=False, title='Confusion matrix'):\n",
    "    if normalize:\n",
    "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cnf_matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return cnf_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(predicted_labels_list, y_test_list):\n",
    "    cnf_matrix = confusion_matrix(y_test_list, predicted_labels_list)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(cnf_matrix, classes=emo_labels, normalize=True, title='SVM + eGeMAPS')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def svm(X, y):\n",
    "    cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_value)\n",
    "    cv_inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed_value)\n",
    "    model = SVC()\n",
    "    ovo = OneVsOneClassifier(model)\n",
    "    space = dict()\n",
    "    space['estimator__C'] = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "    space['estimator__gamma'] = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "    search = BayesSearchCV(ovo, space, scoring='recall_macro', cv=cv_inner, n_jobs= None, verbose=0)\n",
    "    pipeline = make_pipeline(StandardScaler(), search)\n",
    "    scores = cross_validate(pipeline, X, y, scoring=['recall_macro', 'accuracy'], cv=cv_outer, n_jobs=None, verbose=2)\n",
    "    print('____________________ Support Vector Machine ____________________')\n",
    "    print(f\"Weighted Accuracy: {np.mean(scores['test_accuracy'] * 100)}\")\n",
    "    print(f\"Unweighted Accuracy: {np.mean(scores['test_recall_macro']) * 100}\")\n",
    "\n",
    "\n",
    "X, y = opensmile_Functionals()\n",
    "\n",
    "\n",
    "N_SAMPLES = X.shape[0]\n",
    "\n",
    "perm = np.random.permutation(N_SAMPLES)\n",
    "X = X[perm]\n",
    "y = y[perm]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    svm(X, y)\n",
    "\n",
    "    # source:\n",
    "    # Accuracy: 72.95645139237044\n",
    "    # UAR: 58.66650383394545\n",
    "    \n",
    "    # male:\n",
    "    # Accuracy: 76.35305021907651\n",
    "    # UAR: 55.13157619478546\n",
    "    # Time: 3.6 + 16.7 \n",
    "   \n",
    "    # female:\n",
    "    # Accuracy: 69.86364814095091\n",
    "    # UAR: 60.62245031009332\n",
    "    # Time: 2.5 + 12.8\n",
    "    \n",
    "    # modified shemo data:\n",
    "    # Accuracy: 74.40915409507315\n",
    "    # UAR: 59.16878570719483\n",
    "    # Time: 9.7 + 47.5\n",
    "    \n",
    "    # shemo data:\n",
    "    # Accuracy: 74.40915409507315\n",
    "    # UAR: 59.16878570719483\n",
    "    # Time: 8.4 + 44.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
