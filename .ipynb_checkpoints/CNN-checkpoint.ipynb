{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "datapath = 'data'\n",
    "classes = ['W','A','H','F','S','N'] # 6 classes\n",
    "\n",
    "seg_len = 16000 # signal split length (in samples) in time domain\n",
    "seg_ov = int(seg_len*0.5) # 50% overlap\n",
    "\n",
    "def normalize(s):\n",
    "# RMS normalization\n",
    "    new_s = s/np.sqrt(np.sum(np.square((np.abs(s))))/len(s))\n",
    "    return new_s\n",
    "\n",
    "def countclasses(fnames):\n",
    "    dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0}\n",
    "    for name in fnames:\n",
    "        if name[5] in classes:\n",
    "            dict[name[5]]+=1\n",
    "    return dict\n",
    "\n",
    "def data1d(path):\n",
    "\n",
    "\tfnames = os.listdir(datapath)\n",
    "\tdict = countclasses(fnames)\n",
    "\tprint('Total Data',dict)\n",
    "\tnum_cl = len(classes)\n",
    "\ttrain_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0}\n",
    "\ttest_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0}\n",
    "\tval_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0}\n",
    "\n",
    "\tfor i in range(num_cl):\n",
    "\t\tcname =  dict.keys()[i]\n",
    "\t\tcnum = dict[cname]\n",
    "\t\tt = round(0.8*cnum)\n",
    "\t\ttest_dict[cname] = int(cnum - t)\n",
    "\t\tval_dict[cname] = int(round(0.2*t))\n",
    "\t\ttrain_dict[cname] = int(t - val_dict[cname])\n",
    "\t\tprint('Class:',cname,'train:',train_dict[cname],'val:',val_dict[cname],'test:',test_dict[cname])\n",
    "\t\t\n",
    "\tx_train = []\n",
    "\ty_train = []\n",
    "\tx_test = []\n",
    "\ty_test = []\n",
    "\tx_val = []\n",
    "\ty_val = []\n",
    "\n",
    "\tcount = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0}\n",
    "\n",
    "\tfor name in fnames:\n",
    "\t\tif name[3] in classes:\n",
    "\t\t\tsig,fs = librosa.load(datapath+'/'+name, sr=16000)\n",
    "\t\t\t# normalize signal\n",
    "\t\t\tdata = normalize(sig)\n",
    "\t\t\tif(len(data) < seg_len):\n",
    "\t\t\t\tpad_len = int(seg_len - len(data))\n",
    "\t\t\t\tpad_rem = int(pad_len % 2)\n",
    "\t\t\t\tpad_len /= 2\n",
    "\t\t\t\tsignal = np.pad(data,(int(pad_len), int(pad_len+pad_rem)),'constant',constant_values=0)\n",
    "\t\t\telif(len(data) > seg_len):\n",
    "\t\t\t\tsignal = []\n",
    "\t\t\t\tend = seg_len\n",
    "\t\t\t\tst = 0\n",
    "\t\t\t\twhile(end < len(data)):\n",
    "\t\t\t\t\tsignal.append(data[st:end])\n",
    "\t\t\t\t\tst = st + seg_ov\n",
    "\t\t\t\t\tend = st + seg_len\n",
    "\t\t\t\tsignal = np.array(signal)\n",
    "\t\t\t\tif(end >= len(data)):\n",
    "\t\t\t\t\tnum_zeros = int(end-len(data))\n",
    "\t\t\t\t\tif(num_zeros > 0):\n",
    "\t\t\t\t\t\tn1 = np.array(data[st:end])\n",
    "\t\t\t\t\t\tn2 = np.zeros([num_zeros])\n",
    "\t\t\t\t\t\ts = np.concatenate([n1,n2],0)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\ts = np.array(data[int(st):int(end)])\n",
    "\t\t\t\tsignal = np.vstack([signal,s])\n",
    "\t\t\telse:\n",
    "\t\t\t\tsignal = data\n",
    "\n",
    "\t\t\tif(count[name[3]] < train_dict[name[3]]):\n",
    "\t\t\t\tif(signal.ndim>1):\n",
    "\t\t\t\t\tfor i in range(signal.shape[0]):\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tx_train.append(signal[i])\n",
    "\t\t\t\t\t\ty_train.append(name[3])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_train.append(signal)\n",
    "\t\t\t\t\ty_train.append(name[3])\n",
    "\t\t\telse:\n",
    "\t\t\t\tif((count[name[3]]-train_dict[name[3]]) < val_dict[name[3]]):\n",
    "\t\t\t\t\tif(signal.ndim>1):\n",
    "\t\t\t\t\t\tfor i in range(signal.shape[0]):\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tx_val.append(signal[i])\n",
    "\t\t\t\t\t\t\ty_val.append(name[3])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tx_val.append(signal)\n",
    "\t\t\t\t\t\ty_val.append(name[3])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif(signal.ndim>1):\n",
    "\t\t\t\t\t\tfor i in range(signal.shape[0]):\n",
    "\t\t\t\t\t\t\tx_test.append(signal[i])\n",
    "\t\t\t\t\t\t\ty_test.append(name[3])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tx_test.append(signal)\n",
    "\t\t\t\t\t\ty_test.append(name[3])\n",
    "\t\t\tcount[name[3]]+=1\n",
    "\treturn np.float32(x_train),y_train,np.float32(x_test),y_test,np.float32(x_val),y_val\n",
    "\n",
    "def string2num(y):\n",
    "\ty1 = []\n",
    "\tfor i in y:\n",
    "\t\tif(i == classes[0]):\n",
    "\t\t\ty1.append(0)\n",
    "\t\telif(i == classes[1]):\n",
    "\t\t\ty1.append(1)\n",
    "\t\telif(i == classes[2]):\n",
    "\t\t\ty1.append(2)\n",
    "\t\telif(i == classes[3]):\n",
    "\t\t\ty1.append(3)\n",
    "\t\telif(i == classes[4]):\n",
    "\t\t\ty1.append(4)\n",
    "\t\telse:\n",
    "\t\t\ty1.append(5)\n",
    "\ty1 = np.float32(np.array(y1))\n",
    "\treturn y1\n",
    "\n",
    "def load_data():\n",
    "\tx_tr,y_tr,x_t,y_t,x_v,y_v = data1d(datapath)\n",
    "\ty_tr = string2num(y_tr)\n",
    "\ty_t = string2num(y_t)\n",
    "\ty_v = string2num(y_v)\n",
    "\treturn x_tr, y_tr, x_t, y_t, x_v, y_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D cnn for SER\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Input,Conv1D,BatchNormalization,MaxPooling1D,LSTM,Dense,Activation,Layer\n",
    "#from emodata1d import load_data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import argparse\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "def emo1d(input_shape, num_classes,args):\n",
    "\t\n",
    "\tmodel = Sequential(name='Emo1D')\n",
    "\t\n",
    "\t# LFLB1\n",
    "\tmodel.add(Conv1D(filters = 64,kernel_size = (3),strides=1,padding='same',data_format='channels_last',input_shape=input_shape))\t\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LFLB2\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size = 3, strides=1,padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LFLB3\n",
    "\tmodel.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LFLB4\n",
    "\tmodel.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LSTM\n",
    "\tmodel.add(LSTM(units=args.num_fc)) \n",
    "\t\t\n",
    "\t#FC\n",
    "\tmodel.add(Dense(units=num_classes,activation='softmax'))\n",
    "\n",
    "\t#Model compilation\t\n",
    "\topt = optimizers.SGD(lr = args.learning_rate, decay=args.decay, momentum=args.momentum, nesterov=True)\n",
    "\tmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emodata1d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-da6bc60a04eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0memodata1d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emodata1d'"
     ]
    }
   ],
   "source": [
    "# 1D cnn for SER\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Input,Conv1D,BatchNormalization,MaxPooling1D,LSTM,Dense,Activation,Layer\n",
    "from emodata1d import load_data\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import argparse\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "def emo1d(input_shape, num_classes,args):\n",
    "\t\n",
    "\tmodel = Sequential(name='Emo1D')\n",
    "\t\n",
    "\t# LFLB1\n",
    "\tmodel.add(Conv1D(filters = 64,kernel_size = (3),strides=1,padding='same',data_format='channels_last',input_shape=input_shape))\t\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LFLB2\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size = 3, strides=1,padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LFLB3\n",
    "\tmodel.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LFLB4\n",
    "\tmodel.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('elu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\n",
    "\t#LSTM\n",
    "\tmodel.add(LSTM(units=args.num_fc)) \n",
    "\t\t\n",
    "\t#FC\n",
    "\tmodel.add(Dense(units=num_classes,activation='softmax'))\n",
    "\n",
    "\t#Model compilation\t\n",
    "\topt = optimizers.SGD(lr = args.learning_rate, decay=args.decay, momentum=args.momentum, nesterov=True)\n",
    "\tmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
